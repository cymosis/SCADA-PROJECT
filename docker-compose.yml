services:
  # ============================================
  # INFRASTRUCTURE LAYER (Kafka, Zookeeper)
  # ============================================

  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - scada-network

  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://host.docker.internal:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_MESSAGE_MAX_BYTES: 2147483647
      KAFKA_REPLICA_FETCH_MAX_BYTES: 2147483647
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 2147483647
    networks:
      - scada-network
    healthcheck:
      test: [ "CMD", "kafka-broker-api-versions", "--bootstrap-server", "kafka:29092" ]
      interval: 10s
      timeout: 10s
      retries: 10

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    depends_on:
      - kafka
    networks:
      - scada-network

  # ============================================
  # STORAGE LAYER (InfluxDB 2.x)
  # ============================================

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: adminpass123
      DOCKER_INFLUXDB_INIT_ORG: nt-scada
      DOCKER_INFLUXDB_INIT_BUCKET: scada_data
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: nt-scada-token-secret-key-12345
    volumes:
      - influxdb_data:/var/lib/influxdb2
    networks:
      - scada-network
    healthcheck:
      test: [ "CMD", "influx", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # VISUALIZATION LAYER (Grafana)
  # ============================================

  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    depends_on:
      - influxdb
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS: ""
    volumes:
      - grafana_data:/var/lib/grafana
      - ./nt-scada/dashboards:/etc/grafana/provisioning/dashboards
      - ./nt-scada/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
    networks:
      - scada-network

  # ============================================
  # STREAM PROCESSING LAYER (Flink)
  # ============================================

  flink-jobmanager:
    image: flink:1.18.0-scala_2.12-java11
    container_name: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
    volumes:
      - ./nt-scada/stream:/opt/flink/jobs
      - flink_checkpoints:/tmp/flink-checkpoints
    networks:
      - scada-network

  flink-taskmanager:
    image: flink:1.18.0-scala_2.12-java11
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        # To scale: Increase numberOfTaskSlots (e.g., 4) to allow more parallel tasks per container
        taskmanager.numberOfTaskSlots: 2
    volumes:
      - ./nt-scada/stream:/opt/flink/jobs
      - flink_checkpoints:/tmp/flink-checkpoints
    networks:
      - scada-network

  # ============================================
  # NT-SCADA DATA PRODUCERS
  # ============================================

  sensor-producer:
    build:
      context: ./nt-scada/producers
      dockerfile: Dockerfile
    container_name: nt-scada-sensor-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      PRODUCER_TYPE: sensor
    networks:
      - scada-network
    restart: unless-stopped

  actuator-producer:
    build:
      context: ./nt-scada/producers
      dockerfile: Dockerfile
    container_name: nt-scada-actuator-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      PRODUCER_TYPE: actuator
    volumes:
      - ./Swat Data:/app/data
    networks:
      - scada-network
    restart: unless-stopped

  # ============================================
  # NT-SCADA STREAM PROCESSOR
  # ============================================

  stream-processor:
    build:
      context: ./nt-scada/stream
      dockerfile: Dockerfile
    container_name: nt-scada-stream-processor
    depends_on:
      - kafka
      - influxdb
      - flink-jobmanager
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: nt-scada-token-secret-key-12345
      INFLUXDB_ORG: nt-scada
      INFLUXDB_BUCKET: scada_data
    volumes:
      - ./nt-scada/batch/models:/app/models
    networks:
      - scada-network
    restart: unless-stopped

  # ============================================
  # NT-SCADA INFLUXDB CONSUMER
  # ============================================

  influx-consumer:
    build:
      context: ./nt-scada/storage
      dockerfile: Dockerfile
    container_name: nt-scada-influx-consumer
    depends_on:
      kafka:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: nt-scada-token-secret-key-12345
      INFLUXDB_ORG: nt-scada
      INFLUXDB_BUCKET: scada_data
    networks:
      - scada-network
    restart: unless-stopped

  # ============================================
  # NT-SCADA BATCH ANALYTICS
  # ============================================

  batch-analytics:
    build:
      context: ./nt-scada/batch
      dockerfile: Dockerfile
    container_name: nt-scada-batch-analytics
    depends_on:
      - influxdb
    environment:
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: nt-scada-token-secret-key-12345
      INFLUXDB_ORG: nt-scada
      INFLUXDB_BUCKET: scada_data
    volumes:
      - ./nt-scada/batch/models:/app/models
      - ./nt-scada/batch/reports:/app/reports
    networks:
      - scada-network

# ============================================
# NETWORKS
# ============================================

networks:
  scada-network:
    driver: bridge

# ============================================
# VOLUMES
# ============================================

volumes:
  influxdb_data:
  grafana_data:
  flink_checkpoints:
