"""
Bulletproof training - keeps all features explicitly
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import joblib

print("="*80)
print("ğŸ¯ Bulletproof Training Script")
print("="*80)

# Load data
print("\nğŸ“‚ Loading data...")
df = pd.read_excel(r'..\data\swat\Normal Data 2023\22June2020 (1).xlsx')
print(f"âœ… Loaded shape: {df.shape}")
print(f"âœ… Columns: {len(df.columns)}")

# Get all features EXCEPT t_stamp
all_columns = list(df.columns)
print(f"\nğŸ“‹ All columns: {all_columns[:5]}...")

features = [col for col in all_columns if col != 't_stamp']
print(f"\nâœ… Feature columns: {len(features)}")
print(f"ğŸ“‹ First 10 features: {features[:10]}")

# Extract features
X = df[features].copy()
print(f"\nâœ… X shape before conversion: {X.shape}")

# Convert EACH column to numeric individually
print("\nğŸ”„ Converting to numeric...")
for i, col in enumerate(features):
    X[col] = pd.to_numeric(X[col], errors='coerce')
    if i % 10 == 0:
        print(f"  Converted {i}/{len(features)} columns...")

print(f"âœ… Conversion complete")

# Fill NaN with 0
print("\nğŸ”„ Filling NaN values...")
X = X.fillna(0)
print(f"âœ… X shape after fillna: {X.shape}")

# Replace inf values
X = X.replace([np.inf, -np.inf], 0)
print(f"âœ… Final X shape: {X.shape}")

# Sample if too large
if len(X) > 5000:
    X = X.sample(n=5000, random_state=42)
    print(f"ğŸ“‰ Sampled to {len(X)} rows")

# Create labels (all normal)
y_normal = np.zeros(len(X))

# Create synthetic attack data
print("\nğŸ”„ Creating attack data...")
n_attacks = min(1000, len(X) // 2)
X_attack = X.sample(n=n_attacks, random_state=42).copy()

# Add anomalies
for col in X_attack.columns:
    if X_attack[col].std() > 0:
        mask = np.random.rand(len(X_attack)) < 0.3
        X_attack.loc[mask, col] *= np.random.uniform(2, 5, mask.sum())

y_attack = np.ones(len(X_attack))

# Combine
print("\nğŸ“Š Combining datasets...")
X_combined = pd.concat([X, X_attack], ignore_index=True)
y_combined = np.concatenate([y_normal, y_attack])

print(f"âœ… Combined shape: {X_combined.shape}")
print(f"âœ… Features in combined data: {X_combined.shape[1]}")
print(f"ğŸ“Š Normal: {sum(y_combined==0)}, Attack: {sum(y_combined==1)}")

# Verify no NaN or inf
X_combined = X_combined.replace([np.inf, -np.inf], 0)
X_combined = X_combined.fillna(0)

# Split
print("\nğŸ“Š Splitting...")
X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y_combined, test_size=0.3, random_state=42
)

print(f"âœ… Train shape: {X_train.shape}")
print(f"âœ… Test shape: {X_test.shape}")

# Scale
print("\nâš–ï¸  Scaling...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"âœ… Scaled train shape: {X_train_scaled.shape}")

# Train
print("\nğŸ¤– Training RandomForest...")
model = RandomForestClassifier(
    n_estimators=50,
    max_depth=10,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train_scaled, y_train)

print("âœ… Training complete!")

# Test
accuracy = model.score(X_test_scaled, y_test)
print(f"\nğŸ“Š Test Accuracy: {accuracy:.3f}")

# Verify feature count
print(f"\nğŸ” Model n_features_in_: {model.n_features_in_}")
print(f"ğŸ” Scaler n_features_in_: {scaler.n_features_in_}")

# Save
print("\nğŸ’¾ Saving...")
joblib.dump(model, 'binary_classifier.pkl')
joblib.dump(scaler, 'scaler.pkl')

print(f"âœ… Model saved: binary_classifier.pkl")
print(f"âœ… Scaler saved: scaler.pkl")

print("\n" + "="*80)
print(f"âœ… SUCCESS! Model trained with {model.n_features_in_} features")
print("="*80)